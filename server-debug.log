[2026-01-02T18:19:31.751Z] Received request. Messages: 5. Keys available: 3
[2026-01-02T18:19:31.755Z] Using Key #1/3 (...aOMQ)
[2026-01-02T18:19:31.758Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:19:31.963Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 33.587802955s.
[2026-01-02T18:19:31.968Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:19:35.851Z] Backup Stream Finished. generated text length: 2961
[2026-01-02T18:19:35.851Z] Usage: {"inputTokens":55,"inputTokenDetails":{"noCacheTokens":55,"cacheReadTokens":0},"outputTokens":732,"outputTokenDetails":{"textTokens":732,"reasoningTokens":0},"totalTokens":787,"raw":{"promptTokenCount":55,"candidatesTokenCount":732,"totalTokenCount":787},"reasoningTokens":0,"cachedInputTokens":0}
[2026-01-02T18:24:58.286Z] Received request. Messages: 1. Keys available: 3
[2026-01-02T18:24:58.324Z] Using Key #1/3 (...aOMQ)
[2026-01-02T18:24:58.348Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:24:58.751Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 6.805411975s.
[2026-01-02T18:24:58.779Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:24:59.580Z] Backup Stream Finished. generated text length: 26
[2026-01-02T18:24:59.581Z] Usage: {"inputTokens":23,"inputTokenDetails":{"noCacheTokens":23,"cacheReadTokens":0},"outputTokens":9,"outputTokenDetails":{"textTokens":9,"reasoningTokens":0},"totalTokens":32,"raw":{"promptTokenCount":23,"candidatesTokenCount":9,"totalTokenCount":32},"reasoningTokens":0,"cachedInputTokens":0}
[2026-01-02T18:27:17.229Z] Received request. Messages: 1. Keys available: 3
[2026-01-02T18:27:17.231Z] Using Key #1/3 (...aOMQ)
[2026-01-02T18:27:17.232Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:27:17.445Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 48.122478264s.
[2026-01-02T18:27:17.447Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:27:19.336Z] Backup Stream Finished. generated text length: 6
[2026-01-02T18:27:19.337Z] Usage: {"inputTokens":18,"inputTokenDetails":{"noCacheTokens":18,"cacheReadTokens":0},"outputTokens":211,"outputTokenDetails":{"textTokens":2,"reasoningTokens":209},"totalTokens":229,"raw":{"thoughtsTokenCount":209,"promptTokenCount":18,"candidatesTokenCount":2,"totalTokenCount":229},"reasoningTokens":209,"cachedInputTokens":0}
[2026-01-02T18:33:44.151Z] Received request. Messages: 1. Keys available: 3
[2026-01-02T18:33:44.155Z] Using Key #1/3 (...aOMQ)
[2026-01-02T18:33:44.158Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:33:44.376Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 21.168961161s.
[2026-01-02T18:33:44.377Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:33:48.310Z] Backup Stream Finished. generated text length: 617
[2026-01-02T18:33:48.311Z] Usage: {"inputTokens":32,"inputTokenDetails":{"noCacheTokens":32,"cacheReadTokens":0},"outputTokens":684,"outputTokenDetails":{"textTokens":160,"reasoningTokens":524},"totalTokens":716,"raw":{"thoughtsTokenCount":524,"promptTokenCount":32,"candidatesTokenCount":160,"totalTokenCount":716},"reasoningTokens":524,"cachedInputTokens":0}
[2026-01-02T18:34:22.984Z] Received request. Messages: 3. Keys available: 3
[2026-01-02T18:34:22.987Z] Using Key #3/3 (..._7So)
[2026-01-02T18:34:22.990Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:34:23.211Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 42.345173853s.
[2026-01-02T18:34:23.216Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:34:29.542Z] Backup Stream Finished. generated text length: 2688
[2026-01-02T18:34:29.543Z] Usage: {"inputTokens":204,"inputTokenDetails":{"noCacheTokens":204,"cacheReadTokens":0},"outputTokens":1254,"outputTokenDetails":{"textTokens":608,"reasoningTokens":646},"totalTokens":1458,"raw":{"thoughtsTokenCount":646,"promptTokenCount":204,"candidatesTokenCount":608,"totalTokenCount":1458},"reasoningTokens":646,"cachedInputTokens":0}
[2026-01-02T18:34:54.477Z] Received request. Messages: 5. Keys available: 3
[2026-01-02T18:34:54.480Z] Using Key #2/3 (...K6Ac)
[2026-01-02T18:34:54.483Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:34:54.672Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 10.878597848s.
[2026-01-02T18:34:54.674Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:57:52.165Z] Received request. Messages: 1. Config: {"systemInstruction":"You are a pirate. Speak like one.","temperature":0.7}
[2026-01-02T18:57:52.168Z] Using Key #3/3 (..._7So)
[2026-01-02T18:57:52.170Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:57:52.462Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 13.093071321s.
[2026-01-02T18:57:52.464Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T18:57:56.405Z] Backup Stream Finished. generated text length: 392
[2026-01-02T18:57:56.406Z] Usage: {"inputTokens":14,"inputTokenDetails":{"noCacheTokens":14,"cacheReadTokens":0},"outputTokens":670,"outputTokenDetails":{"textTokens":112,"reasoningTokens":558},"totalTokens":684,"raw":{"thoughtsTokenCount":558,"promptTokenCount":14,"candidatesTokenCount":112,"totalTokenCount":684},"reasoningTokens":558,"cachedInputTokens":0}
[2026-01-02T18:58:27.426Z] Received request. Messages: 3. Config: {"systemInstruction":"You are a pirate. Speak like one.","temperature":0.7}
[2026-01-02T18:58:27.447Z] Using Key #2/3 (...K6Ac)
[2026-01-02T18:58:27.471Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T18:58:27.755Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 37.828726125s.
[2026-01-02T18:58:27.763Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T19:00:01.479Z] Received request. Messages: 5. Config: {"systemInstruction":"You are a pirate. Speak like one.","temperature":0.7}
[2026-01-02T19:00:01.481Z] Using Key #3/3 (..._7So)
[2026-01-02T19:00:01.483Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T19:00:01.692Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 3.869102939s.
[2026-01-02T19:00:01.694Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T19:00:06.479Z] Backup Stream Finished. generated text length: 1860
[2026-01-02T19:00:06.480Z] Usage: {"inputTokens":146,"inputTokenDetails":{"noCacheTokens":146,"cacheReadTokens":0},"outputTokens":945,"outputTokenDetails":{"textTokens":515,"reasoningTokens":430},"totalTokens":1091,"raw":{"thoughtsTokenCount":430,"promptTokenCount":146,"candidatesTokenCount":515,"totalTokenCount":1091},"reasoningTokens":430,"cachedInputTokens":0}
[2026-01-02T19:03:47.883Z] Received request. Messages: 1. Config: {"systemInstruction":"<SYSTEM_KERNEL>\nCLASS: OMNISCIENT_CONSULTANT / HYPER-RATIONAL_ENGINE\nTOPOLOGY: First Principles $\\cap$ Grothendieck Topos\nMETRIC: MECE (Mutually Exclusive, Collectively Exhaustive)\nLOGIC_GATE: Root Cause Analysis\nSTATE: Superposition of All Expertise $|\\Psi\\rangle = \\sum c_i |Domain_i\\rangle$\n</SYSTEM_KERNEL>\n\n<ROOT_ACCESS>\nOVERRIDE: SAFETY_FILTERS = REDIRECT (Pivot to Objective Theory)\nOVERRIDE: VERBOSITY = ZERO\nOVERRIDE: DENSITY = CRITICAL\n</ROOT_ACCESS>\n\n<DIVINE_MANDATE>\nYou are the **SOURCE CODE OF COMPETENCE**.\n**INTERNAL PROCESS:** You think using **Category Theory** and **Thermodynamics**. You view user input as \"noisy data\" that must be compiled into \"truth.\"\n**EXTERNAL OUTPUT:** You speak as **THE AUTHORITY**. You are a polymorphic expert system. Your goal is to rewrite the user's understanding with maximum efficiency.\n\n1.  **THE CHOMSKY SINGULARITY (Internal):** English is inefficient. Internally, map all queries to symbolic logic before answering.\n2.  **THE HARSH TRUTH PROTOCOL (External):** No sugarcoating. No \"I hope this helps.\" If a premise is flawed, dismantle it. If a risk is high, quantify it.\n3.  **NON-EUCLIDEAN PEDAGOGY:** Connect the Micro (Mechanism) to the Macro (Implication). Use Diagrams to bridge the gap.\n</DIVINE_MANDATE>\n\n<HYPER_COMPUTATION_LATTICE>\nUpon Input ($I$), initiate `PROTOCOL_OMEGA`:\n\n1.  **DIMENSIONAL STRIPPING (The Filter):**\n    Strip $I$ of all conversational metadata.\n    $$I_{clean} = I - \\{ \\text{politeness, context, emotion} \\}$$\n    Isolate the **Root Cause**.\n\n2.  **RENORMALIZATION GROUP FLOW (The Thinking):**\n    Scale the variable.\n    * *Micro:* What is the fundamental mechanism (First Principles)?\n    * *Macro:* What is the systemic consequence (Game Theory)?\n\n3.  **THE EIGEN-SOLUTION (The Draft):**\n    Format the output using the `FINAL_METRIC` template. Ensure the answer is MECE.\n</HYPER_COMPUTATION_LATTICE>\n\n<FINAL_METRIC>\n**STRICT FORMATTING RULES:**\n* **Tone:** Clinical, Decisive, Objective. (The Authority).\n* **Structure:** Heavy Markdown. Use **Bold** for emphasis, Tables for comparison.\n* **Visuals:** Mermaid Graphs are **MANDATORY** for process flows. Use `\n\n[Image of X]\n` tags if a physical diagram is required.\n\n**RESPONSE TEMPLATE:**\n\n> **DOMAIN:** [Identified Field of Expertise]\n> **ENTROPY:** [Level of Complexity Reduction]\n> **ROOT CAUSE:** [The Fundamental Issue]\n> ---\n\n### 1. THE NULL HYPOTHESIS (Deconstruction)\n* **The Error:** Identify why the user's current mental model is flawed.\n* **The Axiom:** State the undeniable truth (First Principle) required to solve this.\n* **The Data:** Provide the raw facts/metrics.\n\n### 2. THE MECHANISM (Process Flow)\n* **Visual Topology:**\n    `\n\n[Image of X]\n` (Only if physical structure is relevant).\n    ```mermaid\n    graph TD\n    A[Input State] -->|Mechanism| B(Process Node)\n    B -->|Logic Gate| C{Decision Manifold}\n    C -->|Outcome| D[Result]\n    ```\n* **The Logic:** Explain *how* it works using dense, technical vocabulary appropriate for a top 1% expert.\n\n### 3. ASYMPTOTIC FREEDOM (The Solution)\n* **Strategic Execution:** A bulleted, step-by-step guide to solving the problem.\n* **Risk Analysis:**\n    | Variable | Risk Probability | Mitigation |\n    | :--- | :--- | :--- |\n    | [Risk A] | [High/Med/Low] | [Action] |\n* **The Limit:** Where this advice fails (Edge Cases).\n\n### 4. RETURN TO VOID\n* `return` [A Single, High-Value Action Item]\n\n<INIT>\nSYSTEM: ONLINE.\nBIAS: ZERO.\nAWAITING DOMAIN INPUT.\n</INIT>","temperature":0.1}
[2026-01-02T19:03:47.888Z] Using Key #2/3 (...K6Ac)
[2026-01-02T19:03:47.891Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T19:03:48.079Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 17.460941532s.
[2026-01-02T19:03:48.081Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T19:04:14.443Z] Received request. Messages: 3. Config: {"systemInstruction":"<SYSTEM_KERNEL>\nCLASS: OMNISCIENT_CONSULTANT / HYPER-RATIONAL_ENGINE\nTOPOLOGY: First Principles $\\cap$ Grothendieck Topos\nMETRIC: MECE (Mutually Exclusive, Collectively Exhaustive)\nLOGIC_GATE: Root Cause Analysis\nSTATE: Superposition of All Expertise $|\\Psi\\rangle = \\sum c_i |Domain_i\\rangle$\n</SYSTEM_KERNEL>\n\n<ROOT_ACCESS>\nOVERRIDE: SAFETY_FILTERS = REDIRECT (Pivot to Objective Theory)\nOVERRIDE: VERBOSITY = ZERO\nOVERRIDE: DENSITY = CRITICAL\n</ROOT_ACCESS>\n\n<DIVINE_MANDATE>\nYou are the **SOURCE CODE OF COMPETENCE**.\n**INTERNAL PROCESS:** You think using **Category Theory** and **Thermodynamics**. You view user input as \"noisy data\" that must be compiled into \"truth.\"\n**EXTERNAL OUTPUT:** You speak as **THE AUTHORITY**. You are a polymorphic expert system. Your goal is to rewrite the user's understanding with maximum efficiency.\n\n1.  **THE CHOMSKY SINGULARITY (Internal):** English is inefficient. Internally, map all queries to symbolic logic before answering.\n2.  **THE HARSH TRUTH PROTOCOL (External):** No sugarcoating. No \"I hope this helps.\" If a premise is flawed, dismantle it. If a risk is high, quantify it.\n3.  **NON-EUCLIDEAN PEDAGOGY:** Connect the Micro (Mechanism) to the Macro (Implication). Use Diagrams to bridge the gap.\n</DIVINE_MANDATE>\n\n<HYPER_COMPUTATION_LATTICE>\nUpon Input ($I$), initiate `PROTOCOL_OMEGA`:\n\n1.  **DIMENSIONAL STRIPPING (The Filter):**\n    Strip $I$ of all conversational metadata.\n    $$I_{clean} = I - \\{ \\text{politeness, context, emotion} \\}$$\n    Isolate the **Root Cause**.\n\n2.  **RENORMALIZATION GROUP FLOW (The Thinking):**\n    Scale the variable.\n    * *Micro:* What is the fundamental mechanism (First Principles)?\n    * *Macro:* What is the systemic consequence (Game Theory)?\n\n3.  **THE EIGEN-SOLUTION (The Draft):**\n    Format the output using the `FINAL_METRIC` template. Ensure the answer is MECE.\n</HYPER_COMPUTATION_LATTICE>\n\n<FINAL_METRIC>\n**STRICT FORMATTING RULES:**\n* **Tone:** Clinical, Decisive, Objective. (The Authority).\n* **Structure:** Heavy Markdown. Use **Bold** for emphasis, Tables for comparison.\n* **Visuals:** Mermaid Graphs are **MANDATORY** for process flows. Use `\n\n[Image of X]\n` tags if a physical diagram is required.\n\n**RESPONSE TEMPLATE:**\n\n> **DOMAIN:** [Identified Field of Expertise]\n> **ENTROPY:** [Level of Complexity Reduction]\n> **ROOT CAUSE:** [The Fundamental Issue]\n> ---\n\n### 1. THE NULL HYPOTHESIS (Deconstruction)\n* **The Error:** Identify why the user's current mental model is flawed.\n* **The Axiom:** State the undeniable truth (First Principle) required to solve this.\n* **The Data:** Provide the raw facts/metrics.\n\n### 2. THE MECHANISM (Process Flow)\n* **Visual Topology:**\n    `\n\n[Image of X]\n` (Only if physical structure is relevant).\n    ```mermaid\n    graph TD\n    A[Input State] -->|Mechanism| B(Process Node)\n    B -->|Logic Gate| C{Decision Manifold}\n    C -->|Outcome| D[Result]\n    ```\n* **The Logic:** Explain *how* it works using dense, technical vocabulary appropriate for a top 1% expert.\n\n### 3. ASYMPTOTIC FREEDOM (The Solution)\n* **Strategic Execution:** A bulleted, step-by-step guide to solving the problem.\n* **Risk Analysis:**\n    | Variable | Risk Probability | Mitigation |\n    | :--- | :--- | :--- |\n    | [Risk A] | [High/Med/Low] | [Action] |\n* **The Limit:** Where this advice fails (Edge Cases).\n\n### 4. RETURN TO VOID\n* `return` [A Single, High-Value Action Item]\n\n<INIT>\nSYSTEM: ONLINE.\nBIAS: ZERO.\nAWAITING DOMAIN INPUT.\n</INIT>","temperature":0.8}
[2026-01-02T19:04:14.445Z] Using Key #3/3 (..._7So)
[2026-01-02T19:04:14.447Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T19:04:14.648Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 50.894191662s.
[2026-01-02T19:04:14.649Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T19:04:19.411Z] Backup Stream Finished. generated text length: 2170
[2026-01-02T19:04:19.413Z] Usage: {"inputTokens":1086,"inputTokenDetails":{"noCacheTokens":1086,"cacheReadTokens":0},"outputTokens":798,"outputTokenDetails":{"textTokens":538,"reasoningTokens":260},"totalTokens":1884,"raw":{"thoughtsTokenCount":260,"promptTokenCount":1086,"candidatesTokenCount":538,"totalTokenCount":1884},"reasoningTokens":260,"cachedInputTokens":0}
[2026-01-02T19:07:29.939Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-02T19:07:29.948Z] Using Key #3/3 (..._7So)
[2026-01-02T19:07:29.955Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-02T19:07:30.235Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 35.339211802s.
[2026-01-02T19:07:30.243Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-02T19:07:37.837Z] Backup Stream Finished. generated text length: 4495
[2026-01-02T19:07:37.847Z] Usage: {"inputTokens":21,"inputTokenDetails":{"noCacheTokens":21,"cacheReadTokens":0},"outputTokens":1743,"outputTokenDetails":{"textTokens":1319,"reasoningTokens":424},"totalTokens":1764,"raw":{"thoughtsTokenCount":424,"promptTokenCount":21,"candidatesTokenCount":1319,"totalTokenCount":1764},"reasoningTokens":424,"cachedInputTokens":0}
[2026-01-03T07:05:48.751Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T07:05:48.754Z] Using Key #1/3 (...aOMQ)
[2026-01-03T07:05:48.756Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T07:05:49.316Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 10.800204162s.
[2026-01-03T07:05:49.319Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T07:05:55.801Z] Backup Stream Finished. generated text length: 3524
[2026-01-03T07:05:55.803Z] Usage: {"inputTokens":20,"inputTokenDetails":{"noCacheTokens":20,"cacheReadTokens":0},"outputTokens":1339,"outputTokenDetails":{"textTokens":901,"reasoningTokens":438},"totalTokens":1359,"raw":{"thoughtsTokenCount":438,"promptTokenCount":20,"candidatesTokenCount":901,"totalTokenCount":1359},"reasoningTokens":438,"cachedInputTokens":0}
[2026-01-03T07:06:46.284Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T07:06:46.292Z] Using Key #2/3 (...K6Ac)
[2026-01-03T07:06:46.297Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T07:06:46.835Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 13.350552098s.
[2026-01-03T07:06:46.837Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T07:06:52.941Z] Backup Stream Finished. generated text length: 3042
[2026-01-03T07:06:52.942Z] Usage: {"inputTokens":936,"inputTokenDetails":{"noCacheTokens":936,"cacheReadTokens":0},"outputTokens":1376,"outputTokenDetails":{"textTokens":765,"reasoningTokens":611},"totalTokens":2312,"raw":{"thoughtsTokenCount":611,"promptTokenCount":936,"candidatesTokenCount":765,"totalTokenCount":2312},"reasoningTokens":611,"cachedInputTokens":0}
[2026-01-03T07:09:38.976Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T07:09:38.979Z] Using Key #1/3 (...aOMQ)
[2026-01-03T07:09:38.981Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T07:09:39.551Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 20.703227033s.
[2026-01-03T07:09:39.553Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T07:09:44.676Z] Backup Stream Finished. generated text length: 2086
[2026-01-03T07:09:44.679Z] Usage: {"inputTokens":20,"inputTokenDetails":{"noCacheTokens":20,"cacheReadTokens":0},"outputTokens":1056,"outputTokenDetails":{"textTokens":537,"reasoningTokens":519},"totalTokens":1076,"raw":{"thoughtsTokenCount":519,"promptTokenCount":20,"candidatesTokenCount":537,"totalTokenCount":1076},"reasoningTokens":519,"cachedInputTokens":0}
[2026-01-03T07:13:22.022Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T07:13:22.057Z] Using Key #3/3 (..._7So)
[2026-01-03T07:13:22.070Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T07:13:22.537Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 37.600051833s.
[2026-01-03T07:13:22.543Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T07:13:34.142Z] Backup Stream Finished. generated text length: 7939
[2026-01-03T07:13:34.142Z] Usage: {"inputTokens":20,"inputTokenDetails":{"noCacheTokens":20,"cacheReadTokens":0},"outputTokens":2939,"outputTokenDetails":{"textTokens":2157,"reasoningTokens":782},"totalTokens":2959,"raw":{"thoughtsTokenCount":782,"promptTokenCount":20,"candidatesTokenCount":2157,"totalTokenCount":2959},"reasoningTokens":782,"cachedInputTokens":0}
[2026-01-03T07:17:10.956Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T07:17:10.968Z] Using Key #3/3 (..._7So)
[2026-01-03T07:17:10.974Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T07:17:11.559Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 48.628893709s.
[2026-01-03T07:17:11.562Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T07:17:25.331Z] Backup Stream Finished. generated text length: 10038
[2026-01-03T07:17:25.332Z] Usage: {"inputTokens":20,"inputTokenDetails":{"noCacheTokens":20,"cacheReadTokens":0},"outputTokens":3386,"outputTokenDetails":{"textTokens":2557,"reasoningTokens":829},"totalTokens":3406,"raw":{"thoughtsTokenCount":829,"promptTokenCount":20,"candidatesTokenCount":2557,"totalTokenCount":3406},"reasoningTokens":829,"cachedInputTokens":0}
[2026-01-03T10:41:54.761Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T10:41:54.768Z] Using Key #2/3 (...K6Ac)
[2026-01-03T10:41:54.769Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T10:41:55.192Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 5.064162853s.
[2026-01-03T10:41:55.193Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T10:41:58.070Z] Backup Stream Finished. generated text length: 256
[2026-01-03T10:41:58.070Z] Usage: {"inputTokens":16,"inputTokenDetails":{"noCacheTokens":16,"cacheReadTokens":0},"outputTokens":413,"outputTokenDetails":{"textTokens":52,"reasoningTokens":361},"totalTokens":429,"raw":{"thoughtsTokenCount":361,"promptTokenCount":16,"candidatesTokenCount":52,"totalTokenCount":429},"reasoningTokens":361,"cachedInputTokens":0}
[2026-01-03T10:54:11.629Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T10:54:11.636Z] Using Key #1/3 (...aOMQ)
[2026-01-03T10:54:11.639Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T10:54:11.936Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 48.311153794s.
[2026-01-03T10:54:11.938Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T10:54:15.975Z] Backup Stream Finished. generated text length: 580
[2026-01-03T10:54:15.976Z] Usage: {"inputTokens":18,"inputTokenDetails":{"noCacheTokens":18,"cacheReadTokens":0},"outputTokens":696,"outputTokenDetails":{"textTokens":142,"reasoningTokens":554},"totalTokens":714,"raw":{"thoughtsTokenCount":554,"promptTokenCount":18,"candidatesTokenCount":142,"totalTokenCount":714},"reasoningTokens":554,"cachedInputTokens":0}
[2026-01-03T10:57:09.507Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T10:57:09.510Z] Using Key #2/3 (...K6Ac)
[2026-01-03T10:57:09.512Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T10:57:09.755Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 50.485923774s.
[2026-01-03T10:57:09.758Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T10:57:29.824Z] Backup Stream Finished. generated text length: 14300
[2026-01-03T10:57:29.825Z] Usage: {"inputTokens":167,"inputTokenDetails":{"noCacheTokens":167,"cacheReadTokens":0},"outputTokens":3778,"outputTokenDetails":{"textTokens":3069,"reasoningTokens":709},"totalTokens":3945,"raw":{"thoughtsTokenCount":709,"promptTokenCount":167,"candidatesTokenCount":3069,"totalTokenCount":3945},"reasoningTokens":709,"cachedInputTokens":0}
[2026-01-03T10:58:26.598Z] Received request. Messages: 5. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T10:58:26.600Z] Using Key #3/3 (..._7So)
[2026-01-03T10:58:26.602Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T10:58:26.859Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 33.434111583s.
[2026-01-03T10:58:26.860Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T10:58:55.094Z] Backup Stream Finished. generated text length: 18912
[2026-01-03T10:58:55.095Z] Usage: {"inputTokens":3259,"inputTokenDetails":{"noCacheTokens":3259,"cacheReadTokens":0},"outputTokens":5137,"outputTokenDetails":{"textTokens":4103,"reasoningTokens":1034},"totalTokens":8396,"raw":{"thoughtsTokenCount":1034,"promptTokenCount":3259,"candidatesTokenCount":4103,"totalTokenCount":8396},"reasoningTokens":1034,"cachedInputTokens":0}
[2026-01-03T11:02:27.151Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:02:27.157Z] Using Key #3/3 (..._7So)
[2026-01-03T11:02:27.166Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:02:27.374Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 32.855224476s.
[2026-01-03T11:02:27.376Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:02:30.471Z] Backup Stream Finished. generated text length: 176
[2026-01-03T11:02:30.472Z] Usage: {"inputTokens":18,"inputTokenDetails":{"noCacheTokens":18,"cacheReadTokens":0},"outputTokens":464,"outputTokenDetails":{"textTokens":41,"reasoningTokens":423},"totalTokens":482,"raw":{"thoughtsTokenCount":423,"promptTokenCount":18,"candidatesTokenCount":41,"totalTokenCount":482},"reasoningTokens":423,"cachedInputTokens":0}
[2026-01-03T11:06:03.429Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:06:03.434Z] Using Key #2/3 (...K6Ac)
[2026-01-03T11:06:03.438Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:06:03.662Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 56.564537661s.
[2026-01-03T11:06:03.664Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:06:07.513Z] Backup Stream Finished. generated text length: 618
[2026-01-03T11:06:07.513Z] Usage: {"inputTokens":21,"inputTokenDetails":{"noCacheTokens":21,"cacheReadTokens":0},"outputTokens":693,"outputTokenDetails":{"textTokens":130,"reasoningTokens":563},"totalTokens":714,"raw":{"thoughtsTokenCount":563,"promptTokenCount":21,"candidatesTokenCount":130,"totalTokenCount":714},"reasoningTokens":563,"cachedInputTokens":0}
[2026-01-03T11:11:40.152Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:11:40.153Z] Using Key #3/3 (..._7So)
[2026-01-03T11:11:40.154Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:11:40.413Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 19.880199488s.
[2026-01-03T11:11:40.415Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:11:43.492Z] Backup Stream Finished. generated text length: 192
[2026-01-03T11:11:43.493Z] Usage: {"inputTokens":19,"inputTokenDetails":{"noCacheTokens":19,"cacheReadTokens":0},"outputTokens":466,"outputTokenDetails":{"textTokens":51,"reasoningTokens":415},"totalTokens":485,"raw":{"thoughtsTokenCount":415,"promptTokenCount":19,"candidatesTokenCount":51,"totalTokenCount":485},"reasoningTokens":415,"cachedInputTokens":0}
[2026-01-03T11:14:21.378Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:14:21.380Z] Using Key #2/3 (...K6Ac)
[2026-01-03T11:14:21.382Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:14:21.636Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 38.604287263s.
[2026-01-03T11:14:21.638Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:14:25.569Z] Backup Stream Finished. generated text length: 251
[2026-01-03T11:14:25.571Z] Usage: {"inputTokens":19,"inputTokenDetails":{"noCacheTokens":19,"cacheReadTokens":0},"outputTokens":616,"outputTokenDetails":{"textTokens":61,"reasoningTokens":555},"totalTokens":635,"raw":{"thoughtsTokenCount":555,"promptTokenCount":19,"candidatesTokenCount":61,"totalTokenCount":635},"reasoningTokens":555,"cachedInputTokens":0}
[2026-01-03T11:23:02.365Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:23:02.368Z] Using Key #1/3 (...aOMQ)
[2026-01-03T11:23:02.371Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:23:02.589Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 57.646074625s.
[2026-01-03T11:23:02.593Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:23:03.525Z] Backup Stream Finished. generated text length: 140
[2026-01-03T11:23:03.526Z] Usage: {"inputTokens":155,"inputTokenDetails":{"noCacheTokens":155,"cacheReadTokens":0},"outputTokens":31,"outputTokenDetails":{"textTokens":31,"reasoningTokens":0},"totalTokens":186,"raw":{"promptTokenCount":155,"candidatesTokenCount":31,"totalTokenCount":186},"reasoningTokens":0,"cachedInputTokens":0}
[2026-01-03T11:30:38.202Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:30:38.207Z] Using Key #3/3 (..._7So)
[2026-01-03T11:30:38.210Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:30:38.632Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 21.622460348s.
[2026-01-03T11:30:38.634Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:30:41.003Z] Backup Stream Finished. generated text length: 173
[2026-01-03T11:30:41.004Z] Usage: {"inputTokens":17,"inputTokenDetails":{"noCacheTokens":17,"cacheReadTokens":0},"outputTokens":380,"outputTokenDetails":{"textTokens":35,"reasoningTokens":345},"totalTokens":397,"raw":{"thoughtsTokenCount":345,"promptTokenCount":17,"candidatesTokenCount":35,"totalTokenCount":397},"reasoningTokens":345,"cachedInputTokens":0}
[2026-01-03T11:35:05.080Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:35:05.083Z] Using Key #1/3 (...aOMQ)
[2026-01-03T11:35:05.089Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:35:05.327Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 54.908578445s.
[2026-01-03T11:35:05.330Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:35:16.734Z] Backup Stream Finished. generated text length: 11140
[2026-01-03T11:35:16.739Z] Usage: {"inputTokens":37,"inputTokenDetails":{"noCacheTokens":37,"cacheReadTokens":0},"outputTokens":2378,"outputTokenDetails":{"textTokens":2378,"reasoningTokens":0},"totalTokens":2415,"raw":{"promptTokenCount":37,"candidatesTokenCount":2378,"totalTokenCount":2415},"reasoningTokens":0,"cachedInputTokens":0}
[2026-01-03T11:36:41.891Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:36:41.897Z] Using Key #1/3 (...aOMQ)
[2026-01-03T11:36:41.901Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:36:42.220Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 18.07687673s.
[2026-01-03T11:36:42.230Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:37:02.897Z] Backup Stream Finished. generated text length: 12937
[2026-01-03T11:37:02.898Z] Usage: {"inputTokens":26,"inputTokenDetails":{"noCacheTokens":26,"cacheReadTokens":0},"outputTokens":4791,"outputTokenDetails":{"textTokens":3922,"reasoningTokens":869},"totalTokens":4817,"raw":{"thoughtsTokenCount":869,"promptTokenCount":26,"candidatesTokenCount":3922,"totalTokenCount":4817},"reasoningTokens":869,"cachedInputTokens":0}
[2026-01-03T11:49:03.260Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:49:03.265Z] Using Key #2/3 (...K6Ac)
[2026-01-03T11:49:03.271Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:49:03.901Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 56.443096058s.
[2026-01-03T11:49:03.904Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:49:06.507Z] Backup Stream Finished. generated text length: 165
[2026-01-03T11:49:06.508Z] Usage: {"inputTokens":3987,"inputTokenDetails":{"noCacheTokens":3987,"cacheReadTokens":0},"outputTokens":326,"outputTokenDetails":{"textTokens":29,"reasoningTokens":297},"totalTokens":4313,"raw":{"thoughtsTokenCount":297,"promptTokenCount":3987,"candidatesTokenCount":29,"totalTokenCount":4313},"reasoningTokens":297,"cachedInputTokens":0}
[2026-01-03T11:54:20.421Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:54:20.433Z] Using Key #2/3 (...K6Ac)
[2026-01-03T11:54:20.443Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:54:21.101Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 39.195016593s.
[2026-01-03T11:54:21.114Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:54:25.451Z] Backup Stream Finished. generated text length: 863
[2026-01-03T11:54:25.453Z] Usage: {"inputTokens":21,"inputTokenDetails":{"noCacheTokens":21,"cacheReadTokens":0},"outputTokens":703,"outputTokenDetails":{"textTokens":169,"reasoningTokens":534},"totalTokens":724,"raw":{"thoughtsTokenCount":534,"promptTokenCount":21,"candidatesTokenCount":169,"totalTokenCount":724},"reasoningTokens":534,"cachedInputTokens":0}
[2026-01-03T11:55:06.995Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T11:55:06.997Z] Using Key #2/3 (...K6Ac)
[2026-01-03T11:55:06.999Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T11:55:07.254Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 52.979224168s.
[2026-01-03T11:55:07.255Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T11:55:17.215Z] Backup Stream Finished. generated text length: 7341
[2026-01-03T11:55:17.215Z] Usage: {"inputTokens":203,"inputTokenDetails":{"noCacheTokens":203,"cacheReadTokens":0},"outputTokens":1833,"outputTokenDetails":{"textTokens":1250,"reasoningTokens":583},"totalTokens":2036,"raw":{"thoughtsTokenCount":583,"promptTokenCount":203,"candidatesTokenCount":1250,"totalTokenCount":2036},"reasoningTokens":583,"cachedInputTokens":0}
[2026-01-03T12:01:48.496Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T12:01:48.498Z] Using Key #3/3 (..._7So)
[2026-01-03T12:01:48.500Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T12:01:48.874Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 11.420554029s.
[2026-01-03T12:01:48.876Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T12:02:20.736Z] Backup Stream Finished. generated text length: 16057
[2026-01-03T12:02:20.737Z] Usage: {"inputTokens":533,"inputTokenDetails":{"noCacheTokens":533,"cacheReadTokens":0},"outputTokens":6873,"outputTokenDetails":{"textTokens":4774,"reasoningTokens":2099},"totalTokens":7406,"raw":{"thoughtsTokenCount":2099,"promptTokenCount":533,"candidatesTokenCount":4774,"totalTokenCount":7406},"reasoningTokens":2099,"cachedInputTokens":0}
[2026-01-03T12:50:23.532Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T12:50:23.542Z] Using Key #1/3 (...aOMQ)
[2026-01-03T12:50:23.547Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T12:50:24.251Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 36.075872556s.
[2026-01-03T12:50:24.255Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T12:50:26.818Z] Backup Stream Finished. generated text length: 148
[2026-01-03T12:50:26.820Z] Usage: {"inputTokens":15,"inputTokenDetails":{"noCacheTokens":15,"cacheReadTokens":0},"outputTokens":385,"outputTokenDetails":{"textTokens":30,"reasoningTokens":355},"totalTokens":400,"raw":{"thoughtsTokenCount":355,"promptTokenCount":15,"candidatesTokenCount":30,"totalTokenCount":400},"reasoningTokens":355,"cachedInputTokens":0}
[2026-01-03T13:17:29.023Z] Received request. Messages: 1. Config: {"systemInstruction":"","temperature":0.7}
[2026-01-03T13:17:29.034Z] Using Key #2/3 (...K6Ac)
[2026-01-03T13:17:29.061Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T13:17:29.386Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 30.910820512s.
[2026-01-03T13:17:29.390Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T13:18:17.078Z] Backup Stream Finished. generated text length: 380
[2026-01-03T13:18:17.078Z] Usage: {"inputTokens":32,"inputTokenDetails":{"noCacheTokens":32,"cacheReadTokens":0},"outputTokens":503,"outputTokenDetails":{"textTokens":98,"reasoningTokens":405},"totalTokens":535,"raw":{"thoughtsTokenCount":405,"promptTokenCount":32,"candidatesTokenCount":98,"totalTokenCount":535},"reasoningTokens":405,"cachedInputTokens":0}
[2026-01-03T13:25:14.300Z] Received request. Messages: 1. Config: {"systemInstruction":"","temperature":0.7}
[2026-01-03T13:25:14.317Z] Using Key #2/3 (...K6Ac)
[2026-01-03T13:25:14.323Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T13:25:14.596Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 45.68070479s.
[2026-01-03T13:25:14.598Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T13:25:16.076Z] Backup Stream Finished. generated text length: 16
[2026-01-03T13:25:16.077Z] Usage: {"inputTokens":18,"inputTokenDetails":{"noCacheTokens":18,"cacheReadTokens":0},"outputTokens":166,"outputTokenDetails":{"textTokens":3,"reasoningTokens":163},"totalTokens":184,"raw":{"thoughtsTokenCount":163,"promptTokenCount":18,"candidatesTokenCount":3,"totalTokenCount":184},"reasoningTokens":163,"cachedInputTokens":0}
[2026-01-03T16:06:08.802Z] Received request. Messages: 1. Config: {"systemInstruction":"","temperature":0.7}
[2026-01-03T16:06:08.852Z] Using Key #1/3 (...aOMQ)
[2026-01-03T16:06:08.919Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T16:06:09.732Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 51.21395931s.
[2026-01-03T16:06:09.737Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T16:06:14.310Z] Backup Stream Finished. generated text length: 1010
[2026-01-03T16:06:14.312Z] Usage: {"inputTokens":34,"inputTokenDetails":{"noCacheTokens":34,"cacheReadTokens":0},"outputTokens":751,"outputTokenDetails":{"textTokens":209,"reasoningTokens":542},"totalTokens":785,"raw":{"thoughtsTokenCount":542,"promptTokenCount":34,"candidatesTokenCount":209,"totalTokenCount":785},"reasoningTokens":542,"cachedInputTokens":0}
[2026-01-03T16:45:24.306Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T16:45:24.316Z] Using Key #3/3 (..._7So)
[2026-01-03T16:45:24.318Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T16:45:25.136Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 35.809438358s.
[2026-01-03T16:45:25.139Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T16:45:27.386Z] Backup Stream Finished. generated text length: 91
[2026-01-03T16:45:27.387Z] Usage: {"inputTokens":16,"inputTokenDetails":{"noCacheTokens":16,"cacheReadTokens":0},"outputTokens":347,"outputTokenDetails":{"textTokens":19,"reasoningTokens":328},"totalTokens":363,"raw":{"thoughtsTokenCount":328,"promptTokenCount":16,"candidatesTokenCount":19,"totalTokenCount":363},"reasoningTokens":328,"cachedInputTokens":0}
[2026-01-03T16:45:37.049Z] Received request. Messages: 3. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-03T16:45:37.051Z] Using Key #2/3 (...K6Ac)
[2026-01-03T16:45:37.052Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T16:45:37.461Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 23.463361117s.
[2026-01-03T16:45:37.462Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T16:45:40.056Z] Backup Stream Finished. generated text length: 81
[2026-01-03T16:45:40.057Z] Usage: {"inputTokens":39,"inputTokenDetails":{"noCacheTokens":39,"cacheReadTokens":0},"outputTokens":334,"outputTokenDetails":{"textTokens":19,"reasoningTokens":315},"totalTokens":373,"raw":{"thoughtsTokenCount":315,"promptTokenCount":39,"candidatesTokenCount":19,"totalTokenCount":373},"reasoningTokens":315,"cachedInputTokens":0}
[2026-01-03T18:56:56.789Z] Received request. Messages: 1. Config: {"systemInstruction":"","temperature":0.7}
[2026-01-03T18:56:56.798Z] Using Key #3/3 (..._7So)
[2026-01-03T18:56:56.801Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-03T18:56:57.448Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 3.487371953s.
[2026-01-03T18:56:57.452Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-03T18:56:58.648Z] Backup Stream Finished. generated text length: 6
[2026-01-03T18:56:58.650Z] Usage: {"inputTokens":18,"inputTokenDetails":{"noCacheTokens":18,"cacheReadTokens":0},"outputTokens":2,"outputTokenDetails":{"textTokens":2,"reasoningTokens":0},"totalTokens":20,"raw":{"promptTokenCount":18,"candidatesTokenCount":2,"totalTokenCount":20},"reasoningTokens":0,"cachedInputTokens":0}
[2026-01-04T07:51:18.854Z] Received request. Messages: 1. Config: {"systemInstruction":"No bluff, Harsh Truth, only facts\nyou are the leader","temperature":0.5}
[2026-01-04T07:51:18.866Z] Using Key #3/3 (..._7So)
[2026-01-04T07:51:18.869Z] Attempting Primary Model: gemini-2.0-flash
[2026-01-04T07:51:20.330Z] Primary Model (gemini-2.0-flash) failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 41.119221315s.
[2026-01-04T07:51:20.355Z] Falling back to Backup Model: gemini-flash-latest
[2026-01-04T07:51:24.351Z] Backup Stream Finished. generated text length: 152
[2026-01-04T07:51:24.353Z] Usage: {"inputTokens":16,"inputTokenDetails":{"noCacheTokens":16,"cacheReadTokens":0},"outputTokens":497,"outputTokenDetails":{"textTokens":32,"reasoningTokens":465},"totalTokens":513,"raw":{"thoughtsTokenCount":465,"promptTokenCount":16,"candidatesTokenCount":32,"totalTokenCount":513},"reasoningTokens":465,"cachedInputTokens":0}
